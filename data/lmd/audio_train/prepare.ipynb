{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LMD training data preparation\n",
    "\n",
    "This notebook prepares the synthetic training audio based on the Lakh MIDI Dataset (LMD). Run `../note_seq/prepare.ipynb` first.\n",
    "\n",
    "The code creates a `wav_16kHz` directory containing the 8-second training segments, a `metadata.json` file with information about each segment, and `pairs_train`, `pairs_val` and `pairs_test` files listing pairs of audio file paths. Note that `pairs_test` is not used in the paper, but the corresponding MIDI files are used to generate the artificial test set in `../audio_test/`.\n",
    "\n",
    "Copyright 2020 InterDigital R&D and Télécom Paris.  \n",
    "Author: Ondřej Cífka"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import concurrent.futures as cf\n",
    "import glob\n",
    "import hashlib\n",
    "import itertools\n",
    "import json\n",
    "import os\n",
    "import pickle\n",
    "import random\n",
    "import re\n",
    "import sys\n",
    "\n",
    "import librosa\n",
    "from natsort import natsorted, ns\n",
    "import note_seq\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pretty_midi\n",
    "import pysndfx\n",
    "import soundfile as sf\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm.auto import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = '../note_seq/data/'\n",
    "OUTPUT_DIR = 'wav_16kHz'\n",
    "TOTAL_FILES = 169556\n",
    "SR = 16000\n",
    "SF_PATHS = {\n",
    "    'train': [\n",
    "        '../../soundfonts/fluid-soundfont-3.1/FluidR3_GM.sf2',\n",
    "        '../../soundfonts/TimGM6mb.sf2',\n",
    "        '../../soundfonts/Arachno SoundFont - Version 1.0.sf2'\n",
    "    ],\n",
    "    'val': [\n",
    "        '../../soundfonts/fluid-soundfont-3.1/FluidR3_GM.sf2',\n",
    "        '../../soundfonts/TimGM6mb.sf2',\n",
    "        '../../soundfonts/Arachno SoundFont - Version 1.0.sf2'\n",
    "    ],\n",
    "    'test': [\n",
    "        '../../soundfonts/TimbresOfHeaven/Timbres Of Heaven (XGM) 3.94.sf2'\n",
    "    ]\n",
    "}\n",
    "\n",
    "# Load data augmentation parameters from metadata_ref.json instead of sampling them randomly.\n",
    "# Set to True to reproduce the dataset from the paper. Set to False if you want to use your own data.\n",
    "USE_REF_METADATA = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_REF_METADATA:\n",
    "    with open('metadata_ref.json') as f:\n",
    "        metadata_ref = json.load(f)\n",
    "    metadata_ref_flat = {key: val for section in metadata_ref for key, val in metadata_ref[section].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_sequence(sequence, instrument_re=None, instrument_ids=None, programs=None, drums=None,\n",
    "                    copy=False):\n",
    "    if copy:\n",
    "        sequence, original_sequence = music_pb2.NoteSequence(), sequence\n",
    "        sequence.CopyFrom(original_sequence)\n",
    "\n",
    "    if isinstance(instrument_re, str):\n",
    "        instrument_re = re.compile(instrument_re)\n",
    "\n",
    "    # Filter the instruments based on name and ID\n",
    "    deleted_ids = set()\n",
    "    if instrument_re is not None:\n",
    "        deleted_ids.update(i.instrument for i in sequence.instrument_infos\n",
    "                           if not instrument_re.search(i.name))\n",
    "    if instrument_ids is not None:\n",
    "        deleted_ids.update(i.instrument for i in sequence.instrument_infos\n",
    "                           if i.instrument not in instrument_ids)\n",
    "    new_infos = [i for i in sequence.instrument_infos if i.instrument not in deleted_ids]\n",
    "    del sequence.instrument_infos[:]\n",
    "    sequence.instrument_infos.extend(new_infos)\n",
    "\n",
    "    # Filter the event collections\n",
    "    for collection in [sequence.notes, sequence.pitch_bends, sequence.control_changes]:\n",
    "        collection_copy = list(collection)\n",
    "        del collection[:]\n",
    "\n",
    "        for event in collection_copy:\n",
    "            if event.instrument in deleted_ids:\n",
    "                continue\n",
    "            if instrument_ids is not None and event.instrument not in instrument_ids:\n",
    "                continue\n",
    "            if programs is not None and event.program not in programs:\n",
    "                continue\n",
    "            if drums is not None and event.is_drum != drums:\n",
    "                continue\n",
    "            collection.add().CopyFrom(event)\n",
    "\n",
    "    return sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_fx(rng):\n",
    "    chain = pysndfx.AudioEffectsChain()\n",
    "    for _ in range(rng.choice([0, 1, 2, 3], p=[0.35, 0.4, 0.2, 0.05])):\n",
    "        effect = rng.choice([\n",
    "            lambda c: c.overdrive(gain=rng.uniform(10, 40)),\n",
    "            lambda c: c.phaser(gain_in=rng.uniform(0.6, 0.9),\n",
    "                               gain_out=rng.uniform(0.66, 0.85),\n",
    "                               delay=rng.power(0.4) * 3 + 1,\n",
    "                               decay=rng.uniform(0.2, 0.45),\n",
    "                               speed=rng.uniform(0.5, 2),\n",
    "                               triangular=rng.choice([True, False])),\n",
    "            lambda c: c.gain(-3).reverb(),\n",
    "            lambda c: c.tremolo(freq=rng.power(0.5) * 14 + 1,\n",
    "                                depth=rng.uniform(20, 60))\n",
    "        ])\n",
    "        effect(chain)\n",
    "    return chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_file(args):\n",
    "    path, sf_paths = args\n",
    "\n",
    "    if USE_REF_METADATA:\n",
    "        meta_key = os.path.splitext(os.path.basename(path))[0]\n",
    "        meta_ref = metadata_ref_flat.get(meta_key)\n",
    "        if meta_ref is None:\n",
    "            return None\n",
    "    else:\n",
    "        # Use filename as seed\n",
    "        seed = os.path.relpath(path, INPUT_DIR).encode()\n",
    "        seed = int.from_bytes(hashlib.sha512(seed).digest(), 'big')\n",
    "        rng = np.random.default_rng(seed=seed)\n",
    "\n",
    "    with open(path, 'rb') as f:\n",
    "        ns = pickle.load(f)\n",
    "    if not ns.instrument_infos:\n",
    "        return None\n",
    "    max_instrument = max(ii.instrument for ii in ns.instrument_infos)\n",
    "    \n",
    "    meta = {\n",
    "        'src_path': os.path.relpath(path, INPUT_DIR)\n",
    "    }\n",
    "\n",
    "    # Pick a random instrument\n",
    "    if USE_REF_METADATA:\n",
    "        instrument, program = meta_ref['instrument'], meta_ref['src_program']\n",
    "    else:\n",
    "        choices = sorted(set((n.instrument, n.program) for n in ns.notes if not n.is_drum))\n",
    "        if not choices:\n",
    "            return None\n",
    "        instrument, program = choices[rng.choice(len(choices))]\n",
    "    filter_sequence(ns, instrument_ids={instrument})\n",
    "    meta['instrument'], meta['src_program'] = instrument, program\n",
    "\n",
    "    # Change the program randomly\n",
    "    if USE_REF_METADATA:\n",
    "        program = meta_ref['program']\n",
    "    else:\n",
    "        if program < 32:  # Keyboards, guitars\n",
    "            program = rng.choice(32)\n",
    "        elif program >= 40 and program < 80:  # Strings, ensemble, brass, reed, pipe\n",
    "            program = 40 + rng.choice(80 - 40)\n",
    "        elif program < 104:\n",
    "            # Pick a random program from the same class\n",
    "            program = program - (program % 8) + rng.choice(8)\n",
    "    meta['program'] = program\n",
    "\n",
    "    for note in ns.notes:\n",
    "        note.program = program\n",
    "\n",
    "    # Pick a random SoundFont\n",
    "    if USE_REF_METADATA:\n",
    "        [sf_path] = [p for p in sf_paths if os.path.basename(p) == meta_ref['soundfont']]\n",
    "    else:\n",
    "        sf_path = rng.choice(sf_paths)\n",
    "    meta['soundfont'] = os.path.basename(sf_path)\n",
    "\n",
    "    # Pick two non-silent segments\n",
    "    boundaries = np.arange(0., ns.total_time, 8.)\n",
    "    if USE_REF_METADATA:\n",
    "        indices = [s['index'] for s in meta_ref['segments']]\n",
    "    else:\n",
    "        onset_counts, _ = np.histogram([n.start_time for n in ns.notes], bins=boundaries)\n",
    "        activity_map = (onset_counts >= 4)  # arbitrary threshold\n",
    "        [candidates] = np.nonzero(activity_map)\n",
    "        if len(candidates) < 2:\n",
    "            return None\n",
    "        indices = rng.choice(candidates, 2, replace=False)\n",
    "    \n",
    "    # Pick random effects\n",
    "    if USE_REF_METADATA:\n",
    "        effects = pysndfx.AudioEffectsChain()\n",
    "        effects.command = meta_ref['effects']\n",
    "    else:\n",
    "        effects = random_fx(rng)\n",
    "    meta['effects'] = effects.command\n",
    "    \n",
    "    meta['segments'] = []\n",
    "    for ii, i in enumerate(indices):\n",
    "        # Extract the chosen segment\n",
    "        segment = note_seq.sequences_lib.extract_subsequence(ns, boundaries[i], boundaries[i + 1])\n",
    "        \n",
    "        # Transpose by a random amount (up to a fourth)\n",
    "        if USE_REF_METADATA:\n",
    "            assert i == meta_ref['segments'][ii]['index']\n",
    "            transposition = meta_ref['segments'][ii]['transposition']\n",
    "        else:\n",
    "            transposition = rng.choice(np.arange(-5, 6))\n",
    "        note_seq.sequences_lib.transpose_note_sequence(segment, transposition, in_place=True)\n",
    "\n",
    "        # Synthesize it\n",
    "        audio = note_seq.midi_synth.fluidsynth(segment, sf2_path=sf_path, sample_rate=SR)\n",
    "        \n",
    "        # Apply effects\n",
    "        if len(audio) > 0:\n",
    "            audio = effects(audio, sample_in=SR)\n",
    "\n",
    "        # Clip to 8 seconds\n",
    "        audio = audio[:8 * SR]\n",
    "\n",
    "        instrument_len = len(str(max_instrument))\n",
    "        i_len = len(str(len(boundaries) + 1))\n",
    "        out_path = os.path.splitext(path)[0] + f'.{str(instrument).zfill(instrument_len)}.{str(i).zfill(i_len)}.wav'\n",
    "        out_path = os.path.join(OUTPUT_DIR, os.path.relpath(out_path, INPUT_DIR))\n",
    "        os.makedirs(os.path.dirname(out_path), exist_ok=True)\n",
    "        sf.write(out_path, audio, SR, subtype='PCM_24')\n",
    "\n",
    "        meta['segments'].append({\n",
    "            'path': os.path.relpath(out_path, OUTPUT_DIR),\n",
    "            'index': i,\n",
    "            'transposition': transposition\n",
    "        })\n",
    "\n",
    "    return meta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -r {OUTPUT_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "01efc808f4a1445d975695d4d736dc27",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='convert train', max=118948.0, style=ProgressStyle(descrip…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f16094d0e11449ffa0820578bd97db5a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='convert val', max=572.0, style=ProgressStyle(description_…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4cc24724f664a8bbefc6279a8925d86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, description='convert test', max=1201.0, style=ProgressStyle(descriptio…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "120721 / 169556 files converted successfully\n"
     ]
    }
   ],
   "source": [
    "os.makedirs(OUTPUT_DIR)\n",
    "\n",
    "if USE_REF_METADATA:\n",
    "    train_paths, val_paths, test_paths = (\n",
    "        [os.path.join(INPUT_DIR, x['src_path']) for x in metadata_ref[k].values()]\n",
    "        for k in ['train', 'val', 'test'])\n",
    "    paths = [*train_paths, *val_paths, *test_paths]\n",
    "else:\n",
    "    paths = list(tqdm(glob.iglob(os.path.join(INPUT_DIR, '**', '*.pickle'), recursive=True), desc='collect', total=TOTAL_FILES))\n",
    "    paths.sort()\n",
    "\n",
    "    np.random.seed(42)\n",
    "    np.random.shuffle(paths)\n",
    "    train_paths, test_paths = train_test_split(paths, test_size=0.01)\n",
    "    train_paths, val_paths = train_test_split(train_paths, test_size=800)\n",
    "\n",
    "metadata = {}\n",
    "with cf.ProcessPoolExecutor(16) as pool:\n",
    "    for path_list, dset in [(train_paths, 'train'), (val_paths, 'val'), (test_paths, 'test')]:\n",
    "        args = [(p, SF_PATHS[dset]) for p in path_list]\n",
    "        metadata[dset] = list(tqdm(\n",
    "            pool.map(process_file, args, chunksize=100),\n",
    "            desc=f'convert {dset}', total=len(path_list)))\n",
    "\n",
    "metadata = {k: [p for p in metadata[k] if p is not None] for k in metadata}\n",
    "\n",
    "print(sum(len(m) for m in metadata.values()), '/', TOTAL_FILES, 'files converted successfully')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "metadata = {k: {os.path.splitext(os.path.basename(m['src_path']))[0]: m for m in metadata[k]}\n",
    "            for k in metadata}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NumPyJSONEncoder(json.JSONEncoder):\n",
    "    def default(self, x):\n",
    "        if isinstance(x, (np.ndarray, np.generic)):\n",
    "            return x.tolist()\n",
    "        else:\n",
    "            return super().default(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('metadata.json', 'w') as f:\n",
    "    json.dump(metadata, f, cls=NumPyJSONEncoder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_tuples(tuples, path, shuffle_items=False):\n",
    "    with open(path, 'w') as f:\n",
    "        for tup in tuples:\n",
    "            if shuffle_items:\n",
    "                tup = np.random.choice(tup, size=len(tup), replace=False)\n",
    "            print(*tup, sep='\\t', file=f)\n",
    "\n",
    "np.random.seed(42)\n",
    "for dset in ['train', 'val', 'test']:\n",
    "    path_pairs = [(os.path.join(OUTPUT_DIR, a['path']), os.path.join(OUTPUT_DIR, b['path']))\n",
    "                  for m in metadata[dset].values() for a, b in [m['segments']]]\n",
    "    path_pairs.sort()\n",
    "    np.random.shuffle(path_pairs)\n",
    "    write_tuples(path_pairs, f'pairs_{dset}', shuffle_items=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    1201 pairs_test\r\n",
      "  118948 pairs_train\r\n",
      "     572 pairs_val\r\n",
      "  120721 total\r\n"
     ]
    }
   ],
   "source": [
    "!wc -l pairs_*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
